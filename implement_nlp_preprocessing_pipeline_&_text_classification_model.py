# -*- coding: utf-8 -*-
"""Implement NLP Preprocessing Pipeline & Text Classification Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pkFuTrIu-eSfxQgyTNpPixSQe1bPObUP
"""

# ======================
# üìå NLP Classification with Hyperparameter Tuning (GridSearchCV) + Visualization
# ======================

# Install libraries
!pip install scikit-learn nltk

# ======================
# 1. Import Libraries
# ======================
import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ======================
# 2. Download NLTK Data
# ======================
nltk.download('punkt')
nltk.download('punkt_tab')   # ‚úÖ Fix for latest NLTK
nltk.download('stopwords')
nltk.download('wordnet')

# ======================
# 3. Load Dataset
# ======================
file_path = "/content/drive/MyDrive/movie_reviews.csv"  # change to your path
df = pd.read_csv(file_path)

print("Dataset Shape:", df.shape)
print(df.head())

# ======================
# 4. Preprocessing Function
# ======================
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

# ======================
# 5. Apply Preprocessing
# ======================
X = df['review']
y = df['sentiment'].map({'pos': 1, 'neg': 0})

X_clean = X.apply(lambda x: preprocess_text(str(x)))

# ======================
# 6. Train-Test Split
# ======================
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y, test_size=0.2, random_state=42
)

# ======================
# 7. TF-IDF Vectorization
# ======================
tfidf = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# ======================
# 8. Hyperparameter Tuning with GridSearchCV
# ======================
param_grids = {
    "Logistic Regression": {
        "C": [0.01, 0.1, 1, 10],
        "solver": ["liblinear", "saga"]
    },
    "Naive Bayes": {
        "alpha": [0.1, 0.5, 1.0, 5.0]
    },
    "SVM": {
        "C": [0.01, 0.1, 1, 10],
        "max_iter": [1000, 2000]
    }
}

models = {
    "Logistic Regression": LogisticRegression(max_iter=5000),
    "Naive Bayes": MultinomialNB(),
    "SVM": LinearSVC()
}

best_models = {}
results = {}

for name, model in models.items():
    print(f"\nüîé Running GridSearchCV for {name} ...")
    grid = GridSearchCV(model, param_grids[name], cv=3, scoring="f1", n_jobs=-1, verbose=1)
    grid.fit(X_train_tfidf, y_train)

    best_models[name] = grid.best_estimator_
    y_pred = best_models[name].predict(X_test_tfidf)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results[name] = {
        "Best Params": grid.best_params_,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1 Score": f1
    }

    print(f"‚úÖ Best Params: {grid.best_params_}")
    print(classification_report(y_test, y_pred))

# ======================
# 9. Confusion Matrix for Best Overall Model
# ======================
best_model_name = max(results, key=lambda x: results[x]["F1 Score"])
print(f"\nüèÜ Best Model: {best_model_name} with F1 = {results[best_model_name]['F1 Score']:.4f}")

best_model = best_models[best_model_name]
y_pred_best = best_model.predict(X_test_tfidf)

cm = confusion_matrix(y_test, y_pred_best)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Neg", "Pos"], yticklabels=["Neg", "Pos"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title(f"Confusion Matrix - {best_model_name}")
plt.show()

# ======================
# 10. Final Results Table
# ======================
results_df = pd.DataFrame(results).T
print("\nüìä Final Model Comparison:")
print(results_df)

# ======================
# 11. Bar Chart Comparison
# ======================
metrics = ["Accuracy", "Precision", "Recall", "F1 Score"]
results_plot = results_df[metrics]

results_plot.plot(kind="bar", figsize=(10,6))
plt.title("Model Performance Comparison")
plt.ylabel("Score")
plt.ylim(0,1)
plt.xticks(rotation=0)
plt.legend(loc="lower right")
plt.show()